{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPelNtpXoj8nXU/7eg7svmZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tigeress06/TACE-prediction/blob/main/HCC_TACE_CNN_Model_code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Image attribution\n",
        "\n"
      ],
      "metadata": {
        "id": "iepIVpvAN_uH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OEQXMZLrtUh9"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clinical_data_path = '/content/HCC-TACE-Seg_clinical_data-V2 copy.csv'\n",
        "clinical_df = pd.read_csv(clinical_data_path)\n",
        "display(clinical_df)"
      ],
      "metadata": {
        "id": "SJW2zuhBtkXu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_success = pd.DataFrame()\n",
        "df_failure = pd.DataFrame()\n",
        "df_success[\"Patient\"] = []\n",
        "df_failure[\"Patient\"] = []"
      ],
      "metadata": {
        "id": "X8ozlPUiuZ5W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sets results of 1 as success and those of 0 as failure for the therapy\n",
        "for ind, row in clinical_df.iterrows():\n",
        "  if row.at[\"Censored_0_progressed_1\"] == 1:\n",
        "    df_success.loc[len(df_success.index)] = row[\"TCIA_ID\"]\n",
        "  else:\n",
        "    df_failure.loc[len(df_failure.index)] = row[\"TCIA_ID\"]"
      ],
      "metadata": {
        "id": "iwT0e274ucu2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install onedrivedownloader"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lk20-KmPugb2",
        "outputId": "00a41e4a-ba56-45d6-8bd3-ff7f765853a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting onedrivedownloader\n",
            "  Downloading onedrivedownloader-1.1.3-py3-none-any.whl (5.1 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from onedrivedownloader) (2.25.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from onedrivedownloader) (4.64.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->onedrivedownloader) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->onedrivedownloader) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->onedrivedownloader) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->onedrivedownloader) (4.0.0)\n",
            "Installing collected packages: onedrivedownloader\n",
            "Successfully installed onedrivedownloader-1.1.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from onedrivedownloader import download"
      ],
      "metadata": {
        "id": "hjisXFkGux1Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The imaging data is called and unzipped from onedrive where it was stored\n",
        "url = 'https://ycsd-my.sharepoint.com/:u:/g/personal/246679_ystu_ycsd_york_va_us/EQsgL9HhN49MoEbXCFM0mFQBlp8fmQJ8CmMJNG4x9Kj_Zw?e=UDtyze'\n",
        "download(url, filename = 'HCC-TACE-Seg pngs', unzip=True, unzip_path=\"./data\")"
      ],
      "metadata": {
        "id": "EB3l7LEeu0XE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "File Manipulation\n",
        "\n",
        "\n",
        "*   Success images are moved to their own folder\n",
        "*   Failure images are moved to their own folder\n",
        "\n"
      ],
      "metadata": {
        "id": "TSsp9yo4OwuC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil"
      ],
      "metadata": {
        "id": "tbqLsM1mu3vG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_path = '/content/data/HCC-TACE-Seg pngs'\n",
        "success_list = df_success['Patient'].tolist()\n",
        "dest_path_success = '/content/Sorted/Success'\n",
        "for dir in success_list:\n",
        "  source = os.path.join(base_path, dir)\n",
        "  if os.path.isdir(source):\n",
        "    shutil.move(source, dest_path_success, copy_function = shutil.copy2)"
      ],
      "metadata": {
        "id": "YVLDiaa0vRLx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "failure_list = df_failure['Patient'].tolist()\n",
        "dest_path_failure = '/content/Sorted/Failure'\n",
        "for dir_1 in failure_list:\n",
        "  source_1 = os.path.join(base_path, dir_1)\n",
        "  if os.path.isdir(source_1):\n",
        "    shutil.move(source_1, dest_path_failure, copy_function = shutil.copy2)"
      ],
      "metadata": {
        "id": "sX6ASWbRvT4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "path = '/content/Sorted/Success'\n",
        "destination_dir = '/content/png/Success'\n",
        "complete_files = []\n",
        "counter_below_hcdir=0\n",
        "\n",
        "for root, dir_names, file_names in os.walk(path):\n",
        "      path = root.split(os.sep)\n",
        "      print( len(path))\n",
        "      print(\"hhh\")\n",
        "      if(len(path) == 4):\n",
        "        counter_below_hcdir=0\n",
        "      if(len(path) == 5):\n",
        "        prefix = os.path.basename(root)\n",
        "\n",
        "      if(len(path) == 6):\n",
        "        counter_below_hcdir=1\n",
        "        print(\"1 counter_below_hcdir=\" , str(counter_below_hcdir))\n",
        "      if(len(path) == 7):\n",
        "        counter_below_hcdir=counter_below_hcdir+1\n",
        "        print(\"1  -- 2 counter_below_hcdir=\" , str(counter_below_hcdir))\n",
        " \n",
        "      print((len(path) - 1) * '---', os.path.basename(root))\n",
        "      for file in file_names:\n",
        "              if(counter_below_hcdir>0):\n",
        "                print(\"3 counter_below_hcdir=\" , str(counter_below_hcdir))\n",
        "                destination_file_name = prefix.strip() + \"_\" + str(counter_below_hcdir) + \"_\"  + str(file.strip())\n",
        "                desti_path = os.path.join(str(destination_dir), str(destination_file_name))\n",
        "                source_path = os.path.join(root, file)\n",
        "                shutil.copy(source_path, desti_path)"
      ],
      "metadata": {
        "id": "NV7uEE0nvW0b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path_1 = '/content/Sorted/Failure'\n",
        "destination_dir_1 = '/content/png/Failure'\n",
        "complete_files_1 = []\n",
        "counter_below_hcdir_1=0\n",
        "\n",
        "for root_1, dir_names_1, file_names_1 in os.walk(path_1):\n",
        "      path_1 = root_1.split(os.sep)\n",
        "      print( len(path_1))\n",
        "      print(\"hhh\")\n",
        "      if(len(path_1) == 4):\n",
        "        counter_below_hcdir_1=0\n",
        "      if(len(path_1) == 5):\n",
        "        prefix_1 = os.path.basename(root_1)\n",
        "\n",
        "      if(len(path_1) == 6):\n",
        "        counter_below_hcdir_1=1\n",
        "        print(\"1 counter_below_hcdir=\" , str(counter_below_hcdir_1))\n",
        "      if(len(path_1) == 7):\n",
        "        counter_below_hcdir_1=counter_below_hcdir_1+1\n",
        "        print(\"1  -- 2 counter_below_hcdir=\" , str(counter_below_hcdir_1))\n",
        " \n",
        "      print((len(path_1) - 1) * '---', os.path.basename(root_1))\n",
        "      for file_1 in file_names_1:\n",
        "              if(counter_below_hcdir_1>0):\n",
        "                print(\"3 counter_below_hcdir=\" , str(counter_below_hcdir_1))\n",
        "                destination_file_name_1 = prefix_1.strip() + \"_\" + str(counter_below_hcdir_1) + \"_\"  + str(file_1.strip())\n",
        "                desti_path_1 = os.path.join(str(destination_dir_1), str(destination_file_name_1))\n",
        "                print(desti_path_1)\n",
        "                source_path_1 = os.path.join(root_1, file_1)\n",
        "                shutil.copy(source_path_1, desti_path_1)"
      ],
      "metadata": {
        "id": "tRCYNPkCvmTU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Image preprocessing"
      ],
      "metadata": {
        "id": "pw9hvK16PELl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import glob"
      ],
      "metadata": {
        "id": "k5i6g5OSwXmA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# count the number of images in the respective classes 0 - failure, 1 - Success\n",
        "ROOT_DIR = '/content/png'\n",
        "number_of_images = {}\n",
        "\n",
        "for dir_2 in os.listdir(ROOT_DIR):\n",
        "  number_of_images[dir_2] = len(os.listdir(os.path.join(ROOT_DIR, dir_2)))"
      ],
      "metadata": {
        "id": "xAcs-ZCswasN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "number_of_images.items()"
      ],
      "metadata": {
        "id": "HIo7wAcHweBL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del number_of_images['.ipynb_checkpoints']"
      ],
      "metadata": {
        "id": "n1RpclsGwg3v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "number_of_images.items()"
      ],
      "metadata": {
        "id": "8fpZG6iiwlb7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "VKpq6wk7woUD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install split-folders[full]"
      ],
      "metadata": {
        "id": "QCwjD-wWwrSb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import splitfolders"
      ],
      "metadata": {
        "id": "FzFhCt0kwt-S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create train (70%), test (15%), and validation (15%) folders\n",
        "input_folder = '/content/png'\n",
        "splitfolders.ratio(input_folder, output=\"dataset\", seed=1337, ratio=(0.7, 0.15, 0.15), group_prefix=None)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4W5OEf-Swz0h",
        "outputId": "49a5e286-cc59-4aa8-9ef4-491435cdc0a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Copying files: 15273 files [00:12, 1236.59 files/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# removes all standard .ipynb_chekpoint folders which will hinder the model building\n",
        "!rm -rf `find -type d -name .ipynb_checkpoints`"
      ],
      "metadata": {
        "id": "sZUjtrLrw5zu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.applications.mobilenet import preprocess_input"
      ],
      "metadata": {
        "id": "Oz22seBLxBH0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The image is preprocessed with a zoom and shear range of [0.2, 1]\n",
        "# The images are also standardized to be 224 x 224\n",
        "# Image manipulation for training data\n",
        "def preprocessingImages(pat):\n",
        "  image_data = ImageDataGenerator(zoom_range=0.2, shear_range=0.2, preprocessing_function=preprocess_input, horizontal_flip=True)\n",
        "  image = image_data.flow_from_directory(directory=pat, target_size=(224,224), batch_size=32, class_mode='binary')\n",
        "\n",
        "  return image"
      ],
      "metadata": {
        "id": "ANFv6v2oxE83"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training data preprocessed\n",
        "pat = '/content/dataset/train'\n",
        "train_data = preprocessingImages(pat)"
      ],
      "metadata": {
        "id": "CRhSdmh0xJPV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.class_indices"
      ],
      "metadata": {
        "id": "__xCJXbsxMSI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The image is preprocessed with available keras preprocess input\n",
        "# The images are also standardized to be 224 x 224\n",
        "# Image manipulation for testing and validation data\n",
        "def preprocessingImages2(pat):\n",
        "  image_data = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "  image = image_data.flow_from_directory(directory=pat, target_size=(224,224), batch_size=32, class_mode='binary')\n",
        "\n",
        "  return image"
      ],
      "metadata": {
        "id": "o8e2toC-xQK1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# testing data preprocessed\n",
        "pat = '/content/dataset/test'\n",
        "test_data = preprocessingImages2(pat)"
      ],
      "metadata": {
        "id": "ISsQInLHxS0G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# validation data preprocessed\n",
        "pat = '/content/dataset/val'\n",
        "val_data = preprocessingImages2(pat)"
      ],
      "metadata": {
        "id": "CuU2EOnnxVBP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model build"
      ],
      "metadata": {
        "id": "9hjr5DblQuA4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.layers import Flatten, Dense\n",
        "from keras.models import Sequential\n",
        "from keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "LPdlXyfhxYCO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create model\n",
        "# ResNet-50 architecture is utilized\n",
        "# The hidden original dense layer was experimented with and 512 neurons gave a good result\n",
        "# The ouput layer is a sigmoid function because this is a binary classification problem\n",
        "resnet_model = Sequential()\n",
        "\n",
        "pretrained_model = tf.keras.applications.resnet50.ResNet50(\n",
        "    include_top=False,\n",
        "    weights='imagenet',\n",
        "    pooling='avg',\n",
        "    classes=2,\n",
        ")\n",
        "for layer in pretrained_model.layers:\n",
        "  layer.trainable=False\n",
        "\n",
        "resnet_model.add(pretrained_model)\n",
        "resnet_model.add(Flatten())\n",
        "resnet_model.add(Dense(512, activation='relu'))\n",
        "resnet_model.add(Dense(1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "xm4ejJtAxbYi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The model is compiled using the adam optimizer and binary crossentropy loss as appropriate for the program\n",
        "resnet_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "QEZcrZM4xrVH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet_model.summary()"
      ],
      "metadata": {
        "id": "wkKnWmOTxwTy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Visualization (for explanation purposes)"
      ],
      "metadata": {
        "id": "OHSURC4rSBZk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import plot_model"
      ],
      "metadata": {
        "id": "hHgwh27K0so4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizes the model and its layers (for explanation purposes - see the project poster)\n",
        "tf.keras.utils.plot_model(\n",
        "    resnet_model,\n",
        "    to_file='model.png',\n",
        "    show_shapes=True,\n",
        "    show_dtype=False,\n",
        "    show_layer_names=True,\n",
        "    rankdir='TB',\n",
        "    expand_nested=False,\n",
        "    dpi=96,\n",
        "    layer_range=None,\n",
        "    show_layer_activations=False\n",
        ")"
      ],
      "metadata": {
        "id": "bQjoIX0E0waC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizes the model's zoom image augmentation (for explanation purposes - see the project poster)\n",
        "from numpy import expand_dims\n",
        "from keras.utils import load_img\n",
        "from keras.utils import img_to_array\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from matplotlib import pyplot\n",
        "# load the image\n",
        "img = load_img('/content/Sample_CT_image.jpg')\n",
        "# convert to numpy array\n",
        "data = img_to_array(img)\n",
        "# expand dimension to one sample\n",
        "samples = expand_dims(data, 0)\n",
        "# create image data augmentation generator\n",
        "datagen = ImageDataGenerator(zoom_range=[0.2,1.0])\n",
        "# prepare iterator\n",
        "it = datagen.flow(samples, batch_size=1)\n",
        "# generate samples and plot\n",
        "for i in range(9):\n",
        " # define subplot\n",
        " pyplot.subplot(330 + 1 + i)\n",
        " # generate batch of images\n",
        " batch = it.next()\n",
        " # convert to unsigned integers for viewing\n",
        " image = batch[0].astype('uint8')\n",
        " # plot raw pixel data\n",
        " pyplot.imshow(image)\n",
        "# show the figure\n",
        "pyplot.show()"
      ],
      "metadata": {
        "id": "YWiuT7SE3iK2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Limiting overfitting"
      ],
      "metadata": {
        "id": "FmVbnuSxSG1t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# limits overfitting in the model the checkpoint and earlystopping\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "# early stopping\n",
        "\n",
        "es = EarlyStopping(monitor='val_accuracy', min_delta=0.01, patience=5, verbose=1, mode='auto')\n",
        "\n",
        "# model checkpoint\n",
        "\n",
        "mc = ModelCheckpoint(monitor='val_accuracy', filepath=\"./bestmodel.h5\", verbose=1, save_best_only = True, mode='auto')\n",
        "cd = [es, mc]"
      ],
      "metadata": {
        "id": "6RkbHRuLxzJX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Training"
      ],
      "metadata": {
        "id": "ElOjUE4iSNQG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model is trained\n",
        "hs = resnet_model.fit(train_data, validation_data=val_data, epochs=30, callbacks=cd)"
      ],
      "metadata": {
        "id": "-xPGvOgcx1_Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Shows training accuracy over time\n",
        "fig1 = plt.gcf()\n",
        "plt.plot(hs.history['accuracy'])\n",
        "plt.plot(hs.history['val_accuracy'])\n",
        "plt.grid()\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.legend(['train', 'validation'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "AFFQSSBqGeT6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Shows training loss over time\n",
        "plt.plot(hs.history['loss'])\n",
        "plt.plot(hs.history['val_loss'])\n",
        "plt.grid()\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.legend(['train', 'validation'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MjmAoiKoHwYU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Testing\n",
        "\n",
        "\n",
        "*   Model resulted in 85.3339% accuracy\n",
        "*   Model resulted in 0.315303 loss\n",
        "\n"
      ],
      "metadata": {
        "id": "2LkN9qp3SbBp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model testing\n",
        "loss, accuracy = resnet_model.evaluate(test_data, verbose=1)\n",
        "print(\"Test: accuracy = %f  ;  loss = %f\" % (accuracy, loss))"
      ],
      "metadata": {
        "id": "LU9QUlLSK0ZU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}